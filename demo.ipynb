{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fcfbafc",
   "metadata": {},
   "source": [
    "Here we demonstrate how we performed our experiments on the Climate Change Twitter Dataset using the DeBERTa-large model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ctscams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240489e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctscams import greedy_souping, ties\n",
    "from ctscams import finetune\n",
    "from ctscams import cluster_sampling, continous_time_series_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8509a45-fca1-4661-969f-9a4afb4eb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to classify tweets from the finetuned model and get the evaluation results\n",
    "def classify_tweets(df, text_col, label_col, model, save_path=\"test_results\",save_results=True):\n",
    "    df[text_col]=df[text_col].astype(str)\n",
    "    df[label_col]=df[label_col].astype(str)\n",
    "    device = 0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "    classifier = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=model,\n",
    "        tokenizer=model,\n",
    "        device=device,\n",
    "        truncation=True,  \n",
    "        max_length=512,   \n",
    "        padding=\"max_length\"  \n",
    "    )\n",
    "    \n",
    "    outcomes, probs, pred_labels = [], [], []\n",
    "    for text in tqdm_notebook(df[text_col]):  \n",
    "        preds = classifier(text, return_all_scores=True)\n",
    "        outcomes.append(preds)\n",
    "        \n",
    "        # Extract probabilities and predicted label\n",
    "        label_scores = {entry['label']: entry['score'] for entry in preds[0]}\n",
    "        probs.append(list(label_scores.values()))\n",
    "        pred_labels.append(max(label_scores, key=label_scores.get))\n",
    "    df[\"predicted_label\"] = pred_labels\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    labels = df[label_col].tolist()\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred_labels, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, pred_labels)\n",
    "    \n",
    "    # Ensure labels are correctly one-hot encoded for AUROC & AUPRC\n",
    "    label_dummies = pd.get_dummies(labels).reindex(columns=label_scores.keys(), fill_value=0)\n",
    "    \n",
    "    auroc = roc_auc_score(label_dummies, probs, average=\"weighted\", multi_class=\"ovr\")  \n",
    "    auprc = average_precision_score(label_dummies, probs, average=\"weighted\")\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auroc': auroc,\n",
    "        'auprc': auprc\n",
    "    }\n",
    "    print(results)\n",
    "    # Save results\n",
    "    if save_results==True:\n",
    "        metrics_path = f\"{save_path}/metrics/{model}.json\"\n",
    "        os.makedirs(os.path.dirname(metrics_path), exist_ok=True)\n",
    "        with open(metrics_path, \"w\") as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "\n",
    "        print(\"Results saved at:\", metrics_path)\n",
    "        roc_prc_results = {\n",
    "            \"roc_auc_scores\": auroc,\n",
    "            \"prc_auc_scores\": auprc\n",
    "        }\n",
    "        try:\n",
    "            # Save ROC & PRC values\n",
    "            roc_prc_path = f\"{save_path}/roc_and_prc_curves/{model}.json\"\n",
    "            os.makedirs(os.path.dirname(roc_prc_path), exist_ok=True)\n",
    "            with open(roc_prc_path, \"w\") as f:\n",
    "                json.dump(roc_prc_results, f, indent=4)\n",
    "            print(\"ROC & PRC scores saved at:\", roc_prc_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving ROC & PRC scores at {roc_prc_path}: {e}\")\n",
    "    \n",
    "    # Clear memory\n",
    "    del classifier\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc38f64f",
   "metadata": {},
   "source": [
    "# Part I: Selecting from continous time-series clustering and finetuning a single unified model. \n",
    "\n",
    "We first show how we sample from continous time series clustering and finetune to a single unified model (no merging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bd89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df_climate=pd.read_csv(\"../Data/Climate_change/climate_change_cleaned_data.csv.gz\", compression=\"gzip\", index_col=False)\n",
    "df_climate[\"created_at\"]=pd.to_datetime(df_climate[\"created_at\"])\n",
    "df_climate['sentiment'] = df_climate['sentiment'].replace({2:\"News\",1:\"Pro\",0:\"Neutral\",-1:\"Anti\"})\n",
    "\n",
    "# perform continous time series clustering and selecting based on the clusters\n",
    "df_climate=continous_time_series_clustering(df=df_climate,\n",
    "                                            time_col=\"created_at\",\n",
    "                                            level=\"M\", # NOTE: level refers to the level of granularity of which we wish to cluster: \"M\" here stands for Month, \"YE\" stands for year, etc. \n",
    "                                            plot=False, penalty=0.1) \n",
    "df_climate=cluster_sampling(df=df_climate,sample_size=10000,stratified_col=\"cluster\") #note: stratified co\n",
    "df_climate.to_csv(\"../Data/Climate_change/temp/climate_data_cluster_month.csv.gz\", compression=\"gzip\", index=False)\n",
    "\n",
    "df_climate_filter=df_climate[df_climate[\"selected\"]==1].reset_index(drop=True)\n",
    "for col in df_climate_filter.columns:\n",
    "    if isinstance(df_climate_filter[col].dtype, pd.PeriodDtype):\n",
    "        df_climate_filter[col] = df_climate_filter[col].astype(str)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14136ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb78616819aa4a429898f86f63223df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa96c0ac2e90475db168a71a40a57940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\fine_tuning.py:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4503' max='4503' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4503/4503 30:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.766200</td>\n",
       "      <td>0.579091</td>\n",
       "      <td>0.787213</td>\n",
       "      <td>0.780955</td>\n",
       "      <td>0.784476</td>\n",
       "      <td>0.787213</td>\n",
       "      <td>0.934573</td>\n",
       "      <td>0.869537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.458100</td>\n",
       "      <td>0.744201</td>\n",
       "      <td>0.827173</td>\n",
       "      <td>0.821763</td>\n",
       "      <td>0.825826</td>\n",
       "      <td>0.827173</td>\n",
       "      <td>0.943314</td>\n",
       "      <td>0.892887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.255800</td>\n",
       "      <td>0.902342</td>\n",
       "      <td>0.827173</td>\n",
       "      <td>0.823738</td>\n",
       "      <td>0.824093</td>\n",
       "      <td>0.827173</td>\n",
       "      <td>0.944141</td>\n",
       "      <td>0.892331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ./results/naive_finetuning/continous_clustering_by_month/climate_change\n"
     ]
    }
   ],
   "source": [
    "# finetuning\n",
    "finetune(df=df_climate_filter, model_name=\"microsoft/deberta-v3-large\",cluster_col_name=None,\n",
    "         folder_name=\"naive_finetuning/continous_clustering_by_month/climate_change\",\n",
    "         text_col='message', label_col=\"sentiment\",  label2id={\"Anti\":0,\"Neutral\":1,\"Pro\":2,\"News\":3},\n",
    "         learning_rate=1e-5, warmup_ratio=0.05, weight_decay=0.001,\n",
    "         epochs=3, batch_size=6, early_stopping_patience=2, return_val_data=False)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f369a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2949984da2dc4beca56ccdb721f16dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8178898677116172, 'f1': 0.8148961393780465, 'precision': 0.8141299746319381, 'recall': 0.8178898677116172, 'auroc': 0.9404712417983264, 'auprc': 0.885129044604429}\n"
     ]
    }
   ],
   "source": [
    "# evaluation!\n",
    "df_climate=pd.read_csv(\"../Data/Climate_change/temp/climate_data_cluster_month.csv.gz\", compression=\"gzip\", index_col=False)\n",
    "df_climate=df_climate[df_climate[\"selected\"]==0].reset_index(drop=True)\n",
    "classify_tweets(df_climate, \"message\", \"sentiment\", \n",
    "                model='models/naive_finetuning/continous_clustering_by_month/climate_change/deberta-v3-large/0', \n",
    "                save_path=\"test_results\",\n",
    "                save_results=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37a2470",
   "metadata": {},
   "source": [
    "# Part II: Finetuning each model to a cluster, and merging these models. \n",
    "\n",
    "Here we demonstrate how we:\n",
    "1. Finetune each model to each identified cluster\n",
    "2. Merge these multiple models using `greedy souping` and `TIES` (we demo these as they are the most competitive). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6089eb-68f0-4738-b270-e4df2b2d82f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2689d13547e343df9abb74a90ae7629a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e24532229e449d804f687996676070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c44300b22fe4109b42dd861b02a9272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\fine_tuning.py:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1750/2000 12:25 < 01:46, 2.35 it/s, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.008200</td>\n",
       "      <td>0.578256</td>\n",
       "      <td>0.766467</td>\n",
       "      <td>0.699987</td>\n",
       "      <td>0.674511</td>\n",
       "      <td>0.766467</td>\n",
       "      <td>0.911428</td>\n",
       "      <td>0.843269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.615796</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.826991</td>\n",
       "      <td>0.827614</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.889110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>0.797125</td>\n",
       "      <td>0.820359</td>\n",
       "      <td>0.802899</td>\n",
       "      <td>0.822617</td>\n",
       "      <td>0.820359</td>\n",
       "      <td>0.951706</td>\n",
       "      <td>0.905328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.935553</td>\n",
       "      <td>0.832335</td>\n",
       "      <td>0.827255</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.832335</td>\n",
       "      <td>0.945940</td>\n",
       "      <td>0.905582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.849301</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.836585</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.956288</td>\n",
       "      <td>0.915986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.902601</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.838844</td>\n",
       "      <td>0.842981</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.955355</td>\n",
       "      <td>0.911007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.923621</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.835864</td>\n",
       "      <td>0.837174</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.955457</td>\n",
       "      <td>0.912041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ./results/batch_finetuning/continous_clustering_by_month/climate_change\n",
      "Finetuning!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efaca830dcbf44c5a10a7d92900f9b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d9979748cc4373be3f8f54fbf40c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\fine_tuning.py:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/2000 07:05 < 07:06, 2.35 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.079400</td>\n",
       "      <td>0.810746</td>\n",
       "      <td>0.682635</td>\n",
       "      <td>0.644921</td>\n",
       "      <td>0.617745</td>\n",
       "      <td>0.682635</td>\n",
       "      <td>0.856400</td>\n",
       "      <td>0.753631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.659800</td>\n",
       "      <td>0.622243</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.807530</td>\n",
       "      <td>0.810909</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.912352</td>\n",
       "      <td>0.856231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.438400</td>\n",
       "      <td>0.886712</td>\n",
       "      <td>0.778443</td>\n",
       "      <td>0.773152</td>\n",
       "      <td>0.788050</td>\n",
       "      <td>0.778443</td>\n",
       "      <td>0.895807</td>\n",
       "      <td>0.840841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>1.278994</td>\n",
       "      <td>0.742515</td>\n",
       "      <td>0.740705</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>0.742515</td>\n",
       "      <td>0.895862</td>\n",
       "      <td>0.818604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ./results/batch_finetuning/continous_clustering_by_month/climate_change\n",
      "Finetuning!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f54c681655944d7a5932799a3c3aa46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7e3ecc532e491ba4b100f76687d386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\fine_tuning.py:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/2000 10:38 < 03:33, 2.35 it/s, Epoch 6/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.224400</td>\n",
       "      <td>1.027928</td>\n",
       "      <td>0.526946</td>\n",
       "      <td>0.512099</td>\n",
       "      <td>0.643466</td>\n",
       "      <td>0.526946</td>\n",
       "      <td>0.831582</td>\n",
       "      <td>0.705035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.770500</td>\n",
       "      <td>0.666766</td>\n",
       "      <td>0.736527</td>\n",
       "      <td>0.738457</td>\n",
       "      <td>0.748237</td>\n",
       "      <td>0.736527</td>\n",
       "      <td>0.918181</td>\n",
       "      <td>0.847196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.947703</td>\n",
       "      <td>0.748503</td>\n",
       "      <td>0.740831</td>\n",
       "      <td>0.759312</td>\n",
       "      <td>0.748503</td>\n",
       "      <td>0.909252</td>\n",
       "      <td>0.833343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.254400</td>\n",
       "      <td>1.054902</td>\n",
       "      <td>0.790419</td>\n",
       "      <td>0.786948</td>\n",
       "      <td>0.793408</td>\n",
       "      <td>0.790419</td>\n",
       "      <td>0.918625</td>\n",
       "      <td>0.841096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>1.244387</td>\n",
       "      <td>0.748503</td>\n",
       "      <td>0.743218</td>\n",
       "      <td>0.749372</td>\n",
       "      <td>0.748503</td>\n",
       "      <td>0.916054</td>\n",
       "      <td>0.845992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>1.299375</td>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.765176</td>\n",
       "      <td>0.776051</td>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.916319</td>\n",
       "      <td>0.849673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ./results/batch_finetuning/continous_clustering_by_month/climate_change\n",
      "Finetuning!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5c2c60e2734140919c303139c19a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d560f348e14474a16dd758cd00985d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\fine_tuning.py:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/2000 07:05 < 07:06, 2.35 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.081400</td>\n",
       "      <td>0.868367</td>\n",
       "      <td>0.634731</td>\n",
       "      <td>0.602833</td>\n",
       "      <td>0.660408</td>\n",
       "      <td>0.634731</td>\n",
       "      <td>0.835995</td>\n",
       "      <td>0.749097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>0.641212</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.787940</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>0.911629</td>\n",
       "      <td>0.856239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.395900</td>\n",
       "      <td>0.838099</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.806053</td>\n",
       "      <td>0.808402</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.909561</td>\n",
       "      <td>0.855734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>1.117040</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.805723</td>\n",
       "      <td>0.805532</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.911442</td>\n",
       "      <td>0.846441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ./results/batch_finetuning/continous_clustering_by_month/climate_change\n",
      "Finetuning!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c721d7fce1264b379540d1734f86bf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335c8196f720456bb31539873e2f80a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\fine_tuning.py:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/2000 07:07 < 07:07, 2.34 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.076900</td>\n",
       "      <td>0.747078</td>\n",
       "      <td>0.718563</td>\n",
       "      <td>0.681307</td>\n",
       "      <td>0.656678</td>\n",
       "      <td>0.718563</td>\n",
       "      <td>0.876959</td>\n",
       "      <td>0.767413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.663700</td>\n",
       "      <td>0.639465</td>\n",
       "      <td>0.760479</td>\n",
       "      <td>0.742062</td>\n",
       "      <td>0.739500</td>\n",
       "      <td>0.760479</td>\n",
       "      <td>0.918821</td>\n",
       "      <td>0.845272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>1.286839</td>\n",
       "      <td>0.760479</td>\n",
       "      <td>0.732434</td>\n",
       "      <td>0.745409</td>\n",
       "      <td>0.760479</td>\n",
       "      <td>0.907551</td>\n",
       "      <td>0.820386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206300</td>\n",
       "      <td>1.360590</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>0.770529</td>\n",
       "      <td>0.785305</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>0.891041</td>\n",
       "      <td>0.788058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ./results/batch_finetuning/continous_clustering_by_month/climate_change\n",
      "Finetuning!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3473e4258d0d4b4abd7254a9be870ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f2652c6583486e99235cb606a79b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\fine_tuning.py:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/2000 08:52 < 05:20, 2.34 it/s, Epoch 5/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.170800</td>\n",
       "      <td>0.935695</td>\n",
       "      <td>0.622754</td>\n",
       "      <td>0.601272</td>\n",
       "      <td>0.665724</td>\n",
       "      <td>0.622754</td>\n",
       "      <td>0.820740</td>\n",
       "      <td>0.696387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.718600</td>\n",
       "      <td>0.903063</td>\n",
       "      <td>0.694611</td>\n",
       "      <td>0.692676</td>\n",
       "      <td>0.712390</td>\n",
       "      <td>0.694611</td>\n",
       "      <td>0.862554</td>\n",
       "      <td>0.749116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>1.201689</td>\n",
       "      <td>0.688623</td>\n",
       "      <td>0.677395</td>\n",
       "      <td>0.694791</td>\n",
       "      <td>0.688623</td>\n",
       "      <td>0.865439</td>\n",
       "      <td>0.763749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>1.551955</td>\n",
       "      <td>0.736527</td>\n",
       "      <td>0.726300</td>\n",
       "      <td>0.746840</td>\n",
       "      <td>0.736527</td>\n",
       "      <td>0.863797</td>\n",
       "      <td>0.770118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>1.884521</td>\n",
       "      <td>0.724551</td>\n",
       "      <td>0.715193</td>\n",
       "      <td>0.729573</td>\n",
       "      <td>0.724551</td>\n",
       "      <td>0.855765</td>\n",
       "      <td>0.763548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ./results/batch_finetuning/continous_clustering_by_month/climate_change\n",
      "Deleted: ./results/batch_finetuning/continous_clustering_by_month/climate_change\n"
     ]
    }
   ],
   "source": [
    "# Finetune multiple models, each for one cluster.    \n",
    "df_val=finetune(df=df_climate_filter, model_name=\"microsoft/deberta-v3-large\",\n",
    "                cluster_col_name=\"cluster\", # the difference is here --> we use \"cluster\" instead of none to indicate we want to cluster multiple models based on the \"cluster\" column\n",
    "                folder_name=\"batch_finetuning/continous_clustering_by_month/climate_change\", # the individual models will all be saved here\n",
    "                text_col='message', \n",
    "                label_col=\"sentiment\",  \n",
    "                label2id={\"Anti\":0,\"Neutral\":1,\"Pro\":2,\"News\":3},\n",
    "                learning_rate=1e-5, \n",
    "                warmup_ratio=0.05, \n",
    "                weight_decay=0.001,\n",
    "                epochs=8, \n",
    "                batch_size=6, \n",
    "                early_stopping_patience=2, \n",
    "                return_val_data=True)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8006062",
   "metadata": {},
   "source": [
    "#### Greedy souping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3064cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the models \n",
    "label2id={\"Anti\":0,\"Neutral\":1,\"Pro\":2,\"News\":3}\n",
    "num_labels=4\n",
    "text_col=\"message\"\n",
    "col_label=\"sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6ec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring checkpoints on validation set â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e199fd580f8a4ee1b34189450464c0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n",
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start soup with models/batch_finetuning/continous_clustering_by_month/climate_change/deberta-v3-large\\0  (F1 = 0.7334)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f67c7eef754132a236363b3cd82ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kept   models/batch_finetuning/continous_clustering_by_month/climate_change/deberta-v3-large\\2   (F1 = 0.7465)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped models/batch_finetuning/continous_clustering_by_month/climate_change/deberta-v3-large\\5   (F1 = 0.7411)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped models/batch_finetuning/continous_clustering_by_month/climate_change/deberta-v3-large\\1   (F1 = 0.7372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped models/batch_finetuning/continous_clustering_by_month/climate_change/deberta-v3-large\\4   (F1 = 0.7262)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\OneDrive - Washington University in St. Louis\\Research\\Dissertation\\temporal_sensitive_sentiment_analysis\\Code\\merging.py:139: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=fp16_ok, dtype=torch.float16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped models/batch_finetuning/continous_clustering_by_month/climate_change/deberta-v3-large\\3   (F1 = 0.6408)\n",
      "\n",
      "Greedy soup (2 checkpoints) saved to models/merged_models/continous_clustering_by_month/climate_change/greedy_soup/deberta-v3-large  |  dev F1 = 0.7465\n"
     ]
    }
   ],
   "source": [
    "# we perform greedy souping\n",
    "greedy_souping(\n",
    "    models_folder=\"models/batch_finetuning/continous_clustering_by_month/climate_change/deberta-v3-large\", # where the models are saved\n",
    "    save_path=\"models/merged_models/continous_clustering_by_month/climate_change/greedy_soup/deberta-v3-large\", # where you wish to save your merged model\n",
    "    df_val=df_val,          # your validation dataset\n",
    "    col_label=col_label,\n",
    "    text_col=text_col,\n",
    "    num_labels=num_labels,\n",
    "    label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba3549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abefcc1f34fd4ceaad6dc4bb17d7bbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/greedy_soup/deberta-v3-large.json\n",
      "{'accuracy': 0.78660027695118, 'f1': 0.7840331282744417, 'precision': 0.783088115851741, 'recall': 0.78660027695118, 'auroc': 0.9161061382252383, 'auprc': 0.8479873908663575}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/greedy_soup/deberta-v3-large.json\n"
     ]
    }
   ],
   "source": [
    "results, df=classify_tweets(df_climate, text_col, col_label, \n",
    "                            model=\"models/merged_models/continous_clustering_by_month/climate_change/greedy_soup/deberta-v3-large\", \n",
    "                            save_path=\"test_results\",\n",
    "                            save_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b477c39",
   "metadata": {},
   "source": [
    "#### TIES merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4237d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694a375d7fd84743b61ad5dfeee9651c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577d917ce4fc4867aa0266a8f6d46c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28461428ec6845bab784b5f59e17849d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3336b9d8df48689ae9b9828a773211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d9dce5e0224024862d5e524a46c221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ceb866e2854ea89e682f6b497168dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.1.json\n",
      "{'accuracy': 0.21057884231536927, 'f1': 0.07505335123008579, 'precision': 0.08140339040229401, 'recall': 0.21057884231536927, 'auroc': 0.5478362125591704, 'auprc': 0.38903221853172293}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d194118e5b4ebd85b2cfaa1371b00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3122315ef1342dbb60cbc44c3d43e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bac0ccdafa44d2fa33e57d1874279ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42722c57a3744a3a80131f5bcd8471d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28dfbe978ada452d86b92f2533d3a9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.2.json\n",
      "{'accuracy': 0.4810379241516966, 'f1': 0.3475877535986277, 'precision': 0.2938258820704456, 'recall': 0.4810379241516966, 'auroc': 0.5460783398043437, 'auprc': 0.39187031819741236}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367f29066898410491852727282bf2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9568d5d3c0c477cbcfa2c7e229bc95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1d5054691d415ba756267c7af39995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b952c2a8be4f85b6b288cd0d74f169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b793021e2f014c788ace3d573774ced2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.3.json\n",
      "{'accuracy': 0.2954091816367265, 'f1': 0.2155057732265696, 'precision': 0.5551862232071084, 'recall': 0.2954091816367265, 'auroc': 0.7208290992425666, 'auprc': 0.5212557281260811}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b3ca3690f345dea34a1578280ba41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d6c541d51d4f11bb6a8cff84c46d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5663ffeb4314bd1a66458a1eba083b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c3ae5dd5d4461ca510c282a3cbd20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af26f39aeaa45cc9b74a251178986b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.4.json\n",
      "{'accuracy': 0.563872255489022, 'f1': 0.5018648019624143, 'precision': 0.5907504753802154, 'recall': 0.563872255489022, 'auroc': 0.7717895508739474, 'auprc': 0.6225531323242448}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c568bd7bfd4018b6576a867c95e6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ead32a3989040ed890d1c60cef6882f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e72793927d484aa111a86411e03b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0869a0133c84e318abd7717d35699f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b963f867b7f0407cbaea5c3e9d1380b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.5.json\n",
      "{'accuracy': 0.6437125748502994, 'f1': 0.6124264913394248, 'precision': 0.5920417185706194, 'recall': 0.6437125748502994, 'auroc': 0.8265926367965248, 'auprc': 0.6814830567929643}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78781c1028834ad4b6c0460494c2c872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc6a81c86ae43f08ea1a91be950aeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d415e301ac432a8a10456d5c2a1041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe15691d7b5473385b8efb2561accbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddc74c4f5b545669b0b8c0153979e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.6.json\n",
      "{'accuracy': 0.6586826347305389, 'f1': 0.6060099639202112, 'precision': 0.652188036218563, 'recall': 0.6586826347305389, 'auroc': 0.8381471749734125, 'auprc': 0.7138592360015173}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.6.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50aaa0cf097d4b4c8f6f26cb57c231fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8056daca4fe414bb4b867c60eca1c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06162ed68bd64e48b043cd1b3df10f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd4f75f735640688691e57620a0f74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de80d73531b94375835f451b8b2a1d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.7.json\n",
      "{'accuracy': 0.6736526946107785, 'f1': 0.6541957980673249, 'precision': 0.6570950120977956, 'recall': 0.6736526946107785, 'auroc': 0.8511399125097794, 'auprc': 0.7275732133739866}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.7.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1699666f5384305b5694895dc7eb16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94749c59b2440bdb89e9d70aa55a5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ba1f53c1e949c69c642b65c41c7058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cc0e4723d5445888ea193bfc6c0508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac78d7f09fb44f1b1392ae08e63e7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.8.json\n",
      "{'accuracy': 0.6956087824351297, 'f1': 0.6801211125547015, 'precision': 0.6826708985905787, 'recall': 0.6956087824351297, 'auroc': 0.8584988651517077, 'auprc': 0.742565630617136}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.8.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079f9f70bebd4e3ba4d08114226c34a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36047a42005e43c68937223c511a43ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2654805ca24b898ae22d29f5fce0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16141d7560043bc9ee6592a18d2b5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2893b3c562ba4f99a523f683bb6c72f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.9.json\n",
      "{'accuracy': 0.6956087824351297, 'f1': 0.6824610569532399, 'precision': 0.6913159368745471, 'recall': 0.6956087824351297, 'auroc': 0.8585355333664798, 'auprc': 0.741055346198199}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_0.9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ccc8b05e534c899c60b4c4b37a9849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa94eb15e64e4d1c8df12b06873e7dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79a3d5e0eb140a2bf1051f103cd2e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d294d647614cce86936f803e226946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c6a459b94c46c5ac7cd1ec5a02483c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_1.0.json\n",
      "{'accuracy': 0.6986027944111777, 'f1': 0.6865953707868552, 'precision': 0.6965504691776738, 'recall': 0.6986027944111777, 'auroc': 0.856842365634604, 'auprc': 0.7366059850165382}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_10_1.0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11819ccad1bd4229a3e115fd6402b775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573dec9643e347949b786746e5e821e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c828f9b0d04ab09969953d88ce2f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc1b99a50b846dbb601614331f414d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ff8643b95c4d83aacf9a24391d4c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.1.json\n",
      "{'accuracy': 0.2345309381237525, 'f1': 0.11723967442093448, 'precision': 0.43664472893841033, 'recall': 0.2345309381237525, 'auroc': 0.6101237963270377, 'auprc': 0.4285880366409317}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c309004d1aa4739965c0729736bc199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297c5716d31448019d090bd3f18cc05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cfdcc98c204b629fea2af53b6ae31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a99ec10fa24ab78e69ca34708bf3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40e955075e841eab7826242cb7ca59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.2.json\n",
      "{'accuracy': 0.23652694610778444, 'f1': 0.12588702957501524, 'precision': 0.40003548071951184, 'recall': 0.23652694610778444, 'auroc': 0.6187524371139865, 'auprc': 0.4414289449437183}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6ed1803b8d4fa08de6d0d5b93c3c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0b205f0afa40d1b20b487152ff7218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fc0f8cecca4d7c9d838677851be002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f65297f1912438ea6c6487d6c07fc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629a5abdc5154f4d8867c02f8e2d1ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.3.json\n",
      "{'accuracy': 0.5259481037924152, 'f1': 0.5021267259270917, 'precision': 0.5971128743623099, 'recall': 0.5259481037924152, 'auroc': 0.7252999029819931, 'auprc': 0.5739036874461603}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1f5d960f5a49b39ffc9b36f62c821a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bdd3862f6b497db741f6cd6d84b2e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e41994df0c4eb796c94cc903724d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea10c378560249a294a6032e844a87ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c58d59cbdeb47019f74ad295bdff912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.4.json\n",
      "{'accuracy': 0.6157684630738522, 'f1': 0.5822878733228073, 'precision': 0.6190341515777423, 'recall': 0.6157684630738522, 'auroc': 0.7744143350756636, 'auprc': 0.6287357266358441}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb65f6b57ce8407b8c0704d1a32b948f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed165ea7ec154f50adfc943c79699a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4655d969ac7a4e43b2b51a5353c2adba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66ef4b2ecff4092a1c5fb72f177cb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9f26414b8e48c18116ea26ea984e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.5.json\n",
      "{'accuracy': 0.6467065868263473, 'f1': 0.6263431634391462, 'precision': 0.6442660879303105, 'recall': 0.6467065868263473, 'auroc': 0.8311392651923424, 'auprc': 0.7006382557068738}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be3ccdbdd384cd3972a8cd39a7ec79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fad4d23e2ad4c4f8cda75aef141357f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b5df28454d46f5831735ea221e8bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59dec6621a74a1d94c290bbdf80b558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afac6fef90a49f0b4f3729d896dc7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.6.json\n",
      "{'accuracy': 0.6786427145708582, 'f1': 0.6375828649983487, 'precision': 0.6692180855679944, 'recall': 0.6786427145708582, 'auroc': 0.8526848948203628, 'auprc': 0.7373361912893234}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.6.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44052432b2446028330d10b6eddce2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81648b14c5354c0498dff7036fecf601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5b91626f07423887d569a9cc6f9bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6dc9a7440c4f1b916f326f7f3f5354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfaac3b28b7c41a3a0b6f3ae8c162142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.7.json\n",
      "{'accuracy': 0.6976047904191617, 'f1': 0.6696052364987183, 'precision': 0.6858740758383489, 'recall': 0.6976047904191617, 'auroc': 0.860128747575221, 'auprc': 0.7445020468274196}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.7.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c472f67b79c4518b480bc3058141400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37fe694dd494c0982ff28dc41b5e121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8ae194e4ce40d1bf4021b8a41861c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ea84a635f148da8c316d8f7bc97418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81364ad06a1442f289fb8d1e6b63974f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.8.json\n",
      "{'accuracy': 0.6986027944111777, 'f1': 0.6887577121058736, 'precision': 0.6902918371989719, 'recall': 0.6986027944111777, 'auroc': 0.8595960907425635, 'auprc': 0.7401041734642977}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.8.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae6b4f462a54ff3b176dcf05670f137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873e6a2800674e249f8ebc7c16414b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8657c2fab0db4108a57595697c9ea1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4bd9bd666e4df48363be4db89bb75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa6a334ffb844e3932fb7e9c305108c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.9.json\n",
      "{'accuracy': 0.6986027944111777, 'f1': 0.6899503556788689, 'precision': 0.6979793184320903, 'recall': 0.6986027944111777, 'auroc': 0.8578977430982969, 'auprc': 0.737250661810332}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_0.9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dcda5d44d246478e804713a3d52563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b42128fc036425cb6f751cab9ca71ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79705f9385546b298fe7d07c82b4d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c3c5dbcd3240938bf2fe49ed1b990f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1424c99dd47141d18393cf9b3b224c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_1.0.json\n",
      "{'accuracy': 0.6986027944111777, 'f1': 0.6892297275565517, 'precision': 0.7001771117880585, 'recall': 0.6986027944111777, 'auroc': 0.8571851121008701, 'auprc': 0.7341744653761162}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_20_1.0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3891cb69e1634ed2833b209edd844e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b36ec17d77438ca12178238f79d309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54af8ff660594557a102aafb09ec498b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f7154b0fcb40c0bea0849423a7f703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba4b30fa92f4b27bbd1aa98fc988e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.1.json\n",
      "{'accuracy': 0.20958083832335328, 'f1': 0.07280723911977534, 'precision': 0.044056032079984174, 'recall': 0.20958083832335328, 'auroc': 0.5586583444335808, 'auprc': 0.38789002611107104}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e339da77f6fd4a9db10514495e2da0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf2bfa9c3f0474a801709af8328e948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820e6743ec0f4575abdd30c7dcd4abe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0f0c9238da444589ae36357e1d1622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f100de2ff9a406cb776f11e8d7113e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.2.json\n",
      "{'accuracy': 0.4820359281437126, 'f1': 0.39013109350485975, 'precision': 0.3642820427394625, 'recall': 0.4820359281437126, 'auroc': 0.5901212718395037, 'auprc': 0.4373344307634612}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4876520788304ad29ae2e3a3c779a608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c8b7330c3648caa13598f1b2eab101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969c3c336fe84134a05b6a128d408b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719c0638f1be48d284e368ed2cef94be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b46616937344dfbb34753ee7342c340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.3.json\n",
      "{'accuracy': 0.46407185628742514, 'f1': 0.37362940510984255, 'precision': 0.3143541672327663, 'recall': 0.46407185628742514, 'auroc': 0.5755699952027621, 'auprc': 0.40713578347841856}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaeb3b4494614ef6bb30ce49ca14f1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ee22c33a8447b1b9663cc80595d2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494bd4c888f74716b716e3e71f64653c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26adcbeb85234d409b2f0f2aeeb328b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d48a300463d44aaa889be4eab4dc9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.4.json\n",
      "{'accuracy': 0.5379241516966068, 'f1': 0.5073474520208495, 'precision': 0.5399957681070054, 'recall': 0.5379241516966068, 'auroc': 0.774654499911181, 'auprc': 0.6149196675738695}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97a2d42661b4869986a7a33fbd86e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680d86df0a374cc09b340a80caaaaffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a729b126585347ffba5bc2a75681db6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b8f20335064091b309f355cccee890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816a913e6f154ade873e74021b5e4f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.5.json\n",
      "{'accuracy': 0.6377245508982036, 'f1': 0.581636393030219, 'precision': 0.6356983194494291, 'recall': 0.6377245508982036, 'auroc': 0.8162840344413201, 'auprc': 0.6841880783577753}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b943cd7058342349f28b768d4a86931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adc79ff7d084246bebf59fd16fc998b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24329c45a0144d3a836fe247294c14ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64465a9e6fd1420ebfc14669071367f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce096eb6bea24f208bb25b74d9a3bb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.6.json\n",
      "{'accuracy': 0.6906187624750499, 'f1': 0.6617206994624549, 'precision': 0.6849213518561489, 'recall': 0.6906187624750499, 'auroc': 0.855407920118241, 'auprc': 0.7337713569345622}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.6.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428e0ea829ab45e3af2f83b2ba1e16fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9214360df3f4746a7185ba49b35a008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38b6aaa9bd541c48882ad9dffa5ce8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d4f05bbd3f427c978d02c3781357d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b5232e9eeb4850be07c775dc18f1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.7.json\n",
      "{'accuracy': 0.6976047904191617, 'f1': 0.6854051832166964, 'precision': 0.6875658848786488, 'recall': 0.6976047904191617, 'auroc': 0.8601583780808256, 'auprc': 0.7434571006682305}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.7.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e025b27c8149eeb5d9236952244960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f54937eb2a14d7782e5af1b89971a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7a16bf4ae74f06aa96e0aa5d9dac7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ff27976ed145ceb1ee93c48aa7b555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5066562f958e449b87a80cfec3dced6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.8.json\n",
      "{'accuracy': 0.6916167664670658, 'f1': 0.6838555393921627, 'precision': 0.6881510020132713, 'recall': 0.6916167664670658, 'auroc': 0.8573442880975727, 'auprc': 0.7368830002969883}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.8.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce3e2e7c2f24d53b08b1ecf7e605be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed50357181ad4ecfb6f1bb761e966e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830bad10378f4a88854cdd8355e97ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e60d5e2a204d578361e5ccb1e2f8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7918a4c469ba4516b2727215ea0b5dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.9.json\n",
      "{'accuracy': 0.6856287425149701, 'f1': 0.6792593700745261, 'precision': 0.6898230268290149, 'recall': 0.6856287425149701, 'auroc': 0.8562610208604328, 'auprc': 0.7366075546136934}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_0.9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3093ae5c7e744ba4a80a7fc77c5250cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading fine-tuned models:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68d39d527024af4825071c994540515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Global top-k% trimming:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef766f2597f7496593e90efd2e6d1c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Elect sign & merge:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cff7051c3854afb82ffcd66db52accb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final assembly:   0%|          | 0/393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIES-merged model saved to models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e55a80da75d4077956da443cb3c209d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_1.0.json\n",
      "{'accuracy': 0.6936127744510978, 'f1': 0.6853148855568153, 'precision': 0.6987170959017588, 'recall': 0.6936127744510978, 'auroc': 0.856299113260668, 'auprc': 0.7366383410951107}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/bert-large-uncased_30_1.0.json\n"
     ]
    }
   ],
   "source": [
    "# First we select the optimal parameters from the held-out validation set\n",
    "top_ks=[10,20,30]\n",
    "lambda_scales=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "deberta_save_paths, deberta_lambda_scales,deberta_top_ks,deberta_results,deberta_f_score=[],[],[],[],[]\n",
    "for top_k in tqdm_notebook(top_ks):\n",
    "    for lambda_scale in lambda_scales:\n",
    "        lambda_scale_str = str(lambda_scale).replace('.', '_') \n",
    "        save_path=f\"models/merged_models/continous_clustering_by_month/climate_change/ties/deberta-v3-large_{top_k}_{lambda_scale_str}\"\n",
    "        ties(models_folder=\"models/batch_finetuning/continous_clustering_by_month/climate_change/deberta-v3-large\", \n",
    "             save_path=save_path, base_model_name=\"microsoft/deberta-v3-large\",\n",
    "             num_labels=4,label2id=label2id,top_k=top_k,lambda_scale=lambda_scale)\n",
    "        \n",
    "        results, df=classify_tweets(df_val, 'message', \"sentiment\",   \n",
    "                                    model=save_path, \n",
    "                                    save_path=\"test_results\",\n",
    "                                    save_results=False)\n",
    "        saved_path=f\"test_results/metrics/{save_path}.json\"  \n",
    "        deberta_save_paths.append(save_path)\n",
    "        deberta_lambda_scales.append(lambda_scale)\n",
    "        deberta_top_ks.append(top_k)\n",
    "        deberta_results.append(results)\n",
    "        f_score=float(results[\"f1\"])\n",
    "        deberta_f_score.append(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a18561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best lambda:0.6\n",
      "Best top_k:10\n",
      "Best results:{'accuracy': 0.7544910179640718, 'f1': 0.7413933415380723, 'precision': 0.7561588564437421, 'recall': 0.7544910179640718, 'auroc': 0.913731013267178, 'auprc': 0.8383277881629235}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing out the optimal parameters and the validation results\n",
    "best_index = deberta_f_score.index(max(deberta_f_score))\n",
    "best_lambda=deberta_lambda_scales[best_index]\n",
    "best_top_k=deberta_top_ks[best_index]\n",
    "best_results=deberta_results[best_index]\n",
    "deberta_best_save_path=deberta_save_paths[best_index]\n",
    "print_statement=f'''\n",
    "Best lambda:{best_lambda}\n",
    "Best top_k:{best_top_k}\n",
    "Best results:{best_results}\n",
    "'''\n",
    "\n",
    "print(print_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0de12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f688ed94404500933796c98d46d158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved at: test_results/metrics/models/merged_models/continous_clustering_by_month/climate_change/ties/deberta-v3-large_10_0_6.json\n",
      "{'accuracy': 0.768657376034884, 'f1': 0.7550443343741022, 'precision': 0.7667735762042582, 'recall': 0.768657376034884, 'auroc': 0.9150627671642206, 'auprc': 0.841546060804306}\n",
      "ROC & PRC scores saved at: test_results/roc_and_prc_curves/models/merged_models/continous_clustering_by_month/climate_change/ties/deberta-v3-large_10_0_6.json\n"
     ]
    }
   ],
   "source": [
    "# evaluate!\n",
    "# Now we run the model with the optimal parameters. \n",
    "# NOTE: we have saved the models earlier, so we are simply calling and evaluating the 'best' performing model here. \n",
    "results, df=classify_tweets(df_climate, 'message', \"sentiment\",\n",
    "                            model=deberta_best_save_path, \n",
    "                            save_path=\"test_results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
